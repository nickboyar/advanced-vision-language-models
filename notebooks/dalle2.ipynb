{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06604a95-5d37-4d24-8588-7945a416ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dalle2_pytorch import CLIP\n",
    "\n",
    "clip = CLIP(\n",
    "    dim_text = 512,\n",
    "    dim_image = 512,\n",
    "    dim_latent = 512,\n",
    "    num_text_tokens = 49408,\n",
    "    text_enc_depth = 1,\n",
    "    text_seq_len = 256,\n",
    "    text_heads = 8,\n",
    "    visual_enc_depth = 1,\n",
    "    visual_image_size = 256,\n",
    "    visual_patch_size = 32,\n",
    "    visual_heads = 8,\n",
    "    use_all_token_embeds = True,            # whether to use fine-grained contrastive learning (FILIP)\n",
    "    decoupled_contrastive_learning = True,  # use decoupled contrastive learning (DCL) objective function, removing positive pairs from the denominator of the InfoNCE loss (CLOOB + DCL)\n",
    "    extra_latent_projection = True,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_visual_ssl = True,                  # whether to do self supervised learning on images\n",
    "    visual_ssl_type = 'simclr',             # can be either 'simclr' or 'simsiam', depending on using DeCLIP or SLIP\n",
    "    use_mlm = False,                        # use masked language learning (MLM) on text (DeCLIP)\n",
    "    text_ssl_loss_weight = 0.05,            # weight for text MLM loss\n",
    "    image_ssl_loss_weight = 0.05            # weight for image self-supervised learning loss\n",
    ").cuda()\n",
    "\n",
    "# mock data\n",
    "\n",
    "text = torch.randint(0, 49408, (4, 256)).cuda()\n",
    "images = torch.randn(4, 3, 256, 256).cuda()\n",
    "\n",
    "# train\n",
    "\n",
    "loss = clip(\n",
    "    text,\n",
    "    images,\n",
    "    return_loss = True              # needs to be set to True to return contrastive loss\n",
    ")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# do the above with as many texts and images as possible in a loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2image",
   "language": "python",
   "name": "text2image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
